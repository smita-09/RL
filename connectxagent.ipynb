{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-18T08:18:23.907001Z","iopub.execute_input":"2022-02-18T08:18:23.907637Z","iopub.status.idle":"2022-02-18T08:18:23.921019Z","shell.execute_reply.started":"2022-02-18T08:18:23.907542Z","shell.execute_reply":"2022-02-18T08:18:23.919974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, I am going to RL by building the agent who could learn intelligently and would like to know what is happening in each and every step so bear with me","metadata":{}},{"cell_type":"code","source":"pip install kaggle_environments ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:18:48.645676Z","iopub.execute_input":"2022-02-18T08:18:48.646029Z","iopub.status.idle":"2022-02-18T08:18:58.428836Z","shell.execute_reply.started":"2022-02-18T08:18:48.645993Z","shell.execute_reply":"2022-02-18T08:18:58.427656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make, evaluate\n\n# The reason why we are doing this is because we already have some enviornments available and would like to use the environments and train the agent in there. \nenv = make(\"connectx\", debug=True)\n#This is creating the enviornment now and in this case it is a game for which we are trying to build the model for","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:19:07.375922Z","iopub.execute_input":"2022-02-18T08:19:07.376296Z","iopub.status.idle":"2022-02-18T08:19:07.540473Z","shell.execute_reply.started":"2022-02-18T08:19:07.376255Z","shell.execute_reply":"2022-02-18T08:19:07.53903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, I was just looking the code of the how they actually were making these enviornments and its a long process I mean to write code to actually create environments in the first place so its a long boring process of creating an environment and I think I understood what they are trying to do. And I also looked up that there is actually an environment already made for the you know connectx and that is the reason we are able to import it at the very first place.","metadata":{}},{"cell_type":"code","source":"print(list(env.agents))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:31:52.319964Z","iopub.execute_input":"2022-02-18T08:31:52.320642Z","iopub.status.idle":"2022-02-18T08:31:52.32762Z","shell.execute_reply.started":"2022-02-18T08:31:52.320592Z","shell.execute_reply":"2022-02-18T08:31:52.326825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, now we do have an env and we want to load the agents that have been made for them so right now as we can see that there aere two agents and we want to make an agent so that be more intelligent than at least these agents and train them to be of some good you know.","metadata":{}},{"cell_type":"code","source":"# Two random agents play one game round\nenv.run([\"random\", \"random\"])\n\n# Show the game\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:33:38.031682Z","iopub.execute_input":"2022-02-18T08:33:38.032028Z","iopub.status.idle":"2022-02-18T08:33:38.12746Z","shell.execute_reply.started":"2022-02-18T08:33:38.03199Z","shell.execute_reply":"2022-02-18T08:33:38.126352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2022-02-18T08:36:14.593969Z","iopub.execute_input":"2022-02-18T08:36:14.594294Z","iopub.status.idle":"2022-02-18T08:36:14.598062Z","shell.execute_reply.started":"2022-02-18T08:36:14.594263Z","shell.execute_reply":"2022-02-18T08:36:14.597395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create the agent now and to create an agent we need two things at least for this case and the first one being is the observation and second one is configuratin\nso the next thing would be what the heck is observation and what the heck is config so observation would be something like it gives us information about board and that being how many cols are there and how many rows are there and what do we need in this case to win \nOn the other hand observation tells us about more about agent I would say that it tells us about which cells are empty and which cells are acquired by whom so that is a nice peice of information. ","metadata":{}},{"cell_type":"code","source":"def agent_random(obs, config):\n    'This just selects the valid column'\n    valid_col = [col for col in range(config.columns) if obs.board[col] == 0]\n    return random.choice(valid_col)\n    \ndef agent_middle(obs, config):\n    'This one selects the middle column no matter what'\n    return config.columns//2\n\ndef agent_leftmost(obs, config):\n    'This one selects the leftmost column no matter what'\n    left_col = [col for col in range(config.columns) if obs.board[col] == 0]\n    return left_col[0]","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:04:07.851398Z","iopub.execute_input":"2022-02-18T09:04:07.851924Z","iopub.status.idle":"2022-02-18T09:04:07.857983Z","shell.execute_reply.started":"2022-02-18T09:04:07.851884Z","shell.execute_reply":"2022-02-18T09:04:07.857388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we want to play a game so we would let the agents run in the env","metadata":{}},{"cell_type":"code","source":"env.run([agent_leftmost, agent_random])\nenv.render(mode=\"ipython\")","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:04:08.469822Z","iopub.execute_input":"2022-02-18T09:04:08.470144Z","iopub.status.idle":"2022-02-18T09:04:08.540814Z","shell.execute_reply.started":"2022-02-18T09:04:08.470109Z","shell.execute_reply":"2022-02-18T09:04:08.539907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And now we want to know how are agents are performing so we would like to calculate that and also we can not just decide on the basis of some single game so lets\njust calculate","metadata":{}},{"cell_type":"code","source":"def winning_percentage(agent1, agent2, n_rounds=100):\n    config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # Agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"connectx\", [agent1, agent2], config, [], n_rounds//2)\n    # Agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"connectx\", [agent2, agent1], config, [], n_rounds-n_rounds//2)]\n    # Reversing that cause we would be getting the scores for agent2 and agent and we do not want them to add so reversing that\n    print(\"Agent 1 Win Percentage:\", np.round(outcomes.count([1,-1])/len(outcomes), 2))\n    # Counting the times when agent 1 won and so the outcomes would be to have 1 and -1 where agent 1 won and agent 2 lost so yeah, it does make sense!\n    print(\"Agent 2 Win Percentage:\", np.round(outcomes.count([-1,1])/len(outcomes), 2))\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:15:56.931851Z","iopub.execute_input":"2022-02-18T09:15:56.932383Z","iopub.status.idle":"2022-02-18T09:15:56.940297Z","shell.execute_reply.started":"2022-02-18T09:15:56.932347Z","shell.execute_reply":"2022-02-18T09:15:56.939332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"winning_percentage(agent1=agent_middle, agent2=agent_random)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:16:19.930158Z","iopub.execute_input":"2022-02-18T09:16:19.930473Z","iopub.status.idle":"2022-02-18T09:16:25.679035Z","shell.execute_reply.started":"2022-02-18T09:16:19.93044Z","shell.execute_reply":"2022-02-18T09:16:25.678134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"winning_percentage(agent1=agent_leftmost, agent2=agent_random)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T09:17:23.91333Z","iopub.execute_input":"2022-02-18T09:17:23.913894Z","iopub.status.idle":"2022-02-18T09:17:30.555241Z","shell.execute_reply.started":"2022-02-18T09:17:23.913847Z","shell.execute_reply":"2022-02-18T09:17:30.554099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}